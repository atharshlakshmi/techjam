{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af7cd380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_name</th>\n",
       "      <th>author_name</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>rating_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Haci'nin Yeri - Yigit Lokantasi</td>\n",
       "      <td>Gulsum Akar</td>\n",
       "      <td>We went to Marmaris with my wife for a holiday...</td>\n",
       "      <td>5</td>\n",
       "      <td>taste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Haci'nin Yeri - Yigit Lokantasi</td>\n",
       "      <td>Oguzhan Cetin</td>\n",
       "      <td>During my holiday in Marmaris we ate here to f...</td>\n",
       "      <td>4</td>\n",
       "      <td>menu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Haci'nin Yeri - Yigit Lokantasi</td>\n",
       "      <td>Yasin Kuyu</td>\n",
       "      <td>Prices are very affordable. The menu in the ph...</td>\n",
       "      <td>3</td>\n",
       "      <td>outdoor_atmosphere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Haci'nin Yeri - Yigit Lokantasi</td>\n",
       "      <td>Orhan Kapu</td>\n",
       "      <td>Turkey's cheapest artisan restaurant and its f...</td>\n",
       "      <td>5</td>\n",
       "      <td>indoor_atmosphere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Haci'nin Yeri - Yigit Lokantasi</td>\n",
       "      <td>Ozgur Sati</td>\n",
       "      <td>I don't know what you will look for in terms o...</td>\n",
       "      <td>3</td>\n",
       "      <td>menu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     business_name    author_name  \\\n",
       "0  Haci'nin Yeri - Yigit Lokantasi    Gulsum Akar   \n",
       "1  Haci'nin Yeri - Yigit Lokantasi  Oguzhan Cetin   \n",
       "2  Haci'nin Yeri - Yigit Lokantasi     Yasin Kuyu   \n",
       "3  Haci'nin Yeri - Yigit Lokantasi     Orhan Kapu   \n",
       "4  Haci'nin Yeri - Yigit Lokantasi     Ozgur Sati   \n",
       "\n",
       "                                                text  rating  \\\n",
       "0  We went to Marmaris with my wife for a holiday...       5   \n",
       "1  During my holiday in Marmaris we ate here to f...       4   \n",
       "2  Prices are very affordable. The menu in the ph...       3   \n",
       "3  Turkey's cheapest artisan restaurant and its f...       5   \n",
       "4  I don't know what you will look for in terms o...       3   \n",
       "\n",
       "      rating_category  \n",
       "0               taste  \n",
       "1                menu  \n",
       "2  outdoor_atmosphere  \n",
       "3   indoor_atmosphere  \n",
       "4                menu  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_path = \"../data/clean_data.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202d6209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract lengths of each review\n",
    "df[\"review_length\"] = df[\"text\"].apply(len)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9faf962",
   "metadata": {},
   "source": [
    "### using a smaller subset of the data, df2 to try feature engineering first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845f0274",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "df2 = df.head(30).copy()  # Always copy when modifying\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "tokens_list = []\n",
    "for text in df2[\"text\"]:\n",
    "    doc = nlp(text)\n",
    "    tokens_list.append([token.text for token in doc])\n",
    "\n",
    "df2[\"tokens\"] = tokens_list\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cec2bf7",
   "metadata": {},
   "source": [
    "### we can also train this model for our own needs but idk if it will be easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c8c864",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# 1. Load model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# 2. Encode all texts and reference words\n",
    "text_embeddings = model.encode(df2[\"text\"].tolist(), convert_to_tensor=True)\n",
    "reference_embeddings = model.encode([\"restaurant\", \"food\"], convert_to_tensor=True)\n",
    "\n",
    "# 3. Calculate pairwise cosine similarities\n",
    "similarity_matrix = util.cos_sim(text_embeddings, reference_embeddings)\n",
    "\n",
    "print(similarity_matrix.shape)\n",
    "\n",
    "# 4. For each text, get similarity scores to both references\n",
    "similarity_scores = []\n",
    "for i in range(len(df2)):\n",
    "    # Get similarity scores for this text to both reference words\n",
    "    scores = similarity_matrix[i].tolist()\n",
    "    similarity_scores.append(scores)\n",
    "\n",
    "df2[\"similarity_scores\"] = similarity_scores\n",
    "df2\n",
    "# This will give you a list for each row: [similarity_to_restaurant, similarity_to_food]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2a67e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9764f7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "# Step 2: Load the pre-trained sentiment analysis pipeline\n",
    "sentiment_analyzer = pipeline(\"sentiment-analysis\")\n",
    "labels = []\n",
    "scores = []\n",
    "\n",
    "for text in df2[\"text\"]:\n",
    "    result = sentiment_analyzer(text)[0]  # returns list of dicts\n",
    "    label = result['label']\n",
    "    score = result['score']\n",
    "    labels.append(label)\n",
    "    scores.append(score)\n",
    "\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\" â†’ Sentiment: {label} (confidence: {score:.4f})\\n\")\n",
    "\n",
    "df2[\"sentiment\"] = labels\n",
    "df2[\"confidence score\"] = scores\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea47164",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d1626e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38c34f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
